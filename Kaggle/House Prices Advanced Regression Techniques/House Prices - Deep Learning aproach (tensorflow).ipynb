{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19"
      },
      "cell_type": "markdown",
      "source": "# House Prices - Deep Learning aproach\n\n### obs: this code is from my github(https://github.com/dimitreOliveira/HousePrices) that's why it's so modular\n### obs2: kernel with the EDA and data pre process at https://www.kaggle.com/dimitreoliveira/house-prices-eda-first-kernel"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0"
      },
      "cell_type": "markdown",
      "source": "> ### DEPENDENCIES"
    },
    {
      "metadata": {
        "_uuid": "cd89d6e5fefa7122cf06659443b14b68f823893d",
        "_cell_guid": "f5976028-5c8f-4fa2-84cd-254b41aa9f32",
        "trusted": true,
        "_kg_hide-input": true,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "import csv\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.framework import ops\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c05ced8ccd3da1cf77fff7cb9d38a214cd3808e9",
        "_cell_guid": "ae091b94-4f8c-47f6-965e-40979d3215bc"
      },
      "cell_type": "markdown",
      "source": "### DATASET METHODS"
    },
    {
      "metadata": {
        "_uuid": "3710648b7931f2114069d3a682aa953aead4976c",
        "_cell_guid": "cb500f08-6792-4bad-acfc-c875b25f5bf8",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "def load_data(train_path, test_path):\n    \"\"\"\n    method for data loading\n    :param train_path: path for the train set file\n    :param test_path: path for the test set file\n    :return: a 'pandas' array for each set\n    \"\"\"\n\n    train_data = pd.read_csv(train_path)\n    test_data = pd.read_csv(test_path)\n\n    print(\"number of training examples = \" + str(train_data.shape[0]))\n    print(\"number of test examples = \" + str(test_data.shape[0]))\n    print(\"train shape: \" + str(train_data.shape))\n    print(\"test shape: \" + str(test_data.shape))\n\n    return train_data, test_data\n\n\ndef output_submission(test_ids, predictions, id_column, predction_column, file_name):\n    \"\"\"\n    :param test_ids: vector with test dataset ids\n    :param predictions: vector with test dataset predictions\n    :param id_column: name of the output id column\n    :param predction_column: name of the output predction column\n    :param file_name: string for the output file name\n    :return: output a csv with ids ands predictions\n    \"\"\"\n\n    print('Outputting submission...')\n    with open('submissions/' + file_name, 'w') as submission:\n        writer = csv.writer(submission)\n        writer.writerow([id_column, predction_column])\n        for test_id, test_prediction in zip(test_ids, predictions):\n            writer.writerow([test_id, test_prediction])\n    print('Output complete')\n\n\ndef pre_process_data(df):\n    \"\"\"\n    Perform a number of pre process functions on the data set\n    :param df: pandas data frame\n    :return: processed data frame\n    \"\"\"\n    # one-hot encode categorical values\n    df = pd.get_dummies(df)\n\n    return df\n\n\ndef mini_batches(train_set, train_labels, mini_batch_size):\n    \"\"\"\n    Generate mini batches from the data set (data and labels)\n    :param train_set: data set with the examples\n    :param train_labels: data set with the labels\n    :param mini_batch_size: mini batch size\n    :return: mini batches\n    \"\"\"\n    set_size = train_set.shape[0]\n    batches = []\n    num_complete_minibatches = set_size // mini_batch_size\n\n    for k in range(0, num_complete_minibatches):\n        mini_batch_x = train_set[k * mini_batch_size: (k + 1) * mini_batch_size]\n        mini_batch_y = train_labels[k * mini_batch_size: (k + 1) * mini_batch_size]\n        mini_batch = (mini_batch_x, mini_batch_y)\n        batches.append(mini_batch)\n\n    # Handling the end case (last mini-batch < mini_batch_size)\n    if set_size % mini_batch_size != 0:\n        mini_batch_x = train_set[(set_size - (set_size % mini_batch_size)):]\n        mini_batch_y = train_labels[(set_size - (set_size % mini_batch_size)):]\n        mini_batch = (mini_batch_x, mini_batch_y)\n        batches.append(mini_batch)\n\n    return batches",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e93b79a4b690f60d176930edfa532cceebe62b25",
        "_cell_guid": "5529f316-9cad-42b5-b9f1-272ada900424"
      },
      "cell_type": "markdown",
      "source": "### AUXILIARY MODEL METHODS"
    },
    {
      "metadata": {
        "_uuid": "2e46cf19d65c5d99e29edbd4d4e84d23543e99c9",
        "_cell_guid": "37ce988d-3875-4fa8-b7a5-fcbe85c9ef80",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "def create_placeholders(input_size, output_size):\n    \"\"\"\n    Creates the placeholders for the tensorflow session.\n    :param input_size: scalar, input size\n    :param output_size: scalar, output size\n    :return: X  placeholder for the data input, of shape [None, input_size] and dtype \"float\"\n    :return: Y placeholder for the input labels, of shape [None, output_size] and dtype \"float\"\n    \"\"\"\n\n    x = tf.placeholder(shape=(None, input_size), dtype=tf.float32, name=\"X\")\n    y = tf.placeholder(shape=(None, output_size), dtype=tf.float32, name=\"Y\")\n\n    return x, y\n\n\ndef forward_propagation(x, parameters, keep_prob=1.0, hidden_activation='relu'):\n    \"\"\"\n    Implement forward propagation with dropout for the [LINEAR->RELU]*(L-1)->LINEAR-> computation\n    :param x: data, pandas array of shape (input size, number of examples)\n    :param parameters: output of initialize_parameters()\n    :param keep_prob: probability to keep each node of the layer\n    :param hidden_activation: activation function of the hidden layers\n    :return: last LINEAR value\n    \"\"\"\n\n    a_dropout = x\n    n_layers = len(parameters) // 2  # number of layers in the neural network\n\n    for l in range(1, n_layers):\n        a_prev = a_dropout\n        a_dropout = linear_activation_forward(a_prev, parameters['w%s' % l], parameters['b%s' % l], hidden_activation)\n\n        if keep_prob < 1.0:\n            a_dropout = tf.nn.dropout(a_dropout, keep_prob)\n\n    al = tf.matmul(a_dropout, parameters['w%s' % n_layers]) + parameters['b%s' % n_layers]\n\n    return al\n\n\ndef linear_activation_forward(a_prev, w, b, activation):\n    \"\"\"\n    Implement the forward propagation for the LINEAR->ACTIVATION layer\n    :param a_prev: activations from previous layer (or input data): (size of previous layer, number of examples)\n    :param w: weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    :param b: bias vector, numpy array of shape (size of the current layer, 1)\n    :param activation: the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n    :return: the output of the activation function, also called the post-activation value\n    \"\"\"\n\n    a = None\n    if activation == \"sigmoid\":\n        z = tf.matmul(a_prev, w) + b\n        a = tf.nn.sigmoid(z)\n\n    elif activation == \"relu\":\n        z = tf.matmul(a_prev, w) + b\n        a = tf.nn.relu(z)\n\n    elif activation == \"leaky relu\":\n        z = tf.matmul(a_prev, w) + b\n        a = tf.nn.leaky_relu(z)\n\n    return a\n\n\ndef initialize_parameters(layer_dims):\n    \"\"\"\n    :param layer_dims: python array (list) containing the dimensions of each layer in our network\n    :return: python dictionary containing your parameters \"w1\", \"b1\", ..., \"wn\", \"bn\":\n                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n                    bl -- bias vector of shape (layer_dims[l], 1)\n    \"\"\"\n\n    parameters = {}\n    n_layers = len(layer_dims)\n\n    for l in range(1, n_layers):\n        parameters['w' + str(l)] = tf.get_variable('w' + str(l), [layer_dims[l - 1], layer_dims[l]],\n                                                   initializer=tf.contrib.layers.xavier_initializer())\n        parameters['b' + str(l)] = tf.get_variable('b' + str(l), [layer_dims[l]], initializer=tf.zeros_initializer())\n\n    return parameters\n\n\ndef compute_cost(z3, y):\n    \"\"\"\n    :param z3: output of forward propagation (output of the last LINEAR unit)\n    :param y: \"true\" labels vector placeholder, same shape as Z3\n    :return: Tensor of the cost function (RMSE as it is a regression)\n    \"\"\"\n\n    cost = tf.sqrt(tf.reduce_mean(tf.square(y - z3)))\n\n    return cost\n\n\ndef predict(data, parameters):\n    \"\"\"\n    make a prediction based on a data set and parameters\n    :param data: based data set\n    :param parameters: based parameters\n    :return: array of predictions\n    \"\"\"\n\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n\n        dataset = tf.cast(tf.constant(data), tf.float32)\n        fw_prop_result = forward_propagation(dataset, parameters)\n        prediction = fw_prop_result.eval()\n\n    return prediction\n\n\ndef rmse(predictions, labels):\n    \"\"\"\n    calculate cost between two data sets\n    :param predictions: data set of predictions\n    :param labels: data set of labels (real values)\n    :return: percentage of correct predictions\n    \"\"\"\n\n    prediction_size = predictions.shape[0]\n    prediction_cost = np.sqrt(np.sum(np.square(labels - predictions)) / prediction_size)\n\n    return prediction_cost\n\n\ndef rmsle(predictions, labels):\n    \"\"\"\n    calculate cost between two data sets\n    :param predictions: data set of predictions\n    :param labels: data set of labels (real values)\n    :return: percentage of correct predictions\n    \"\"\"\n\n    prediction_size = predictions.shape[0]\n    prediction_cost = np.sqrt(np.sum(np.square(np.log(predictions + 1) - np.log(labels + 1))) / prediction_size)\n\n    return prediction_cost\n\n\ndef l2_regularizer(cost, l2_beta, parameters, n_layers):\n    \"\"\"\n    Function to apply l2 regularization to the model\n    :param cost: usual cost of the model\n    :param l2_beta: beta value used for the normalization\n    :param parameters: parameters from the model (used to get weights values)\n    :param n_layers: number of layers of the model\n    :return: cost updated\n    \"\"\"\n\n    regularizer = 0\n    for i in range(1, n_layers):\n        regularizer += tf.nn.l2_loss(parameters['w%s' % i])\n\n    cost = tf.reduce_mean(cost + l2_beta * regularizer)\n\n    return cost\n\n\ndef build_submission_name(layers_dims, num_epochs, lr_decay,\n                          learning_rate, l2_beta, keep_prob, minibatch_size, num_examples):\n    \"\"\"\n    builds a string (submission file name), based on the model parameters\n    :param layers_dims: model layers dimensions\n    :param num_epochs: model number of epochs\n    :param lr_decay: model learning rate decay\n    :param learning_rate: model learning rate\n    :param l2_beta: beta used on l2 normalization\n    :param keep_prob: keep probability used on dropout normalization\n    :param minibatch_size: model mini batch size (0 to do not use mini batches)\n    :param num_examples: number of model examples (training data)\n    :return: built string\n    \"\"\"\n    submission_name = 'ly{}-epoch{}.csv' \\\n        .format(layers_dims, num_epochs)\n\n    if lr_decay != 0:\n        submission_name = 'lrdc{}-'.format(lr_decay) + submission_name\n    else:\n        submission_name = 'lr{}-'.format(learning_rate) + submission_name\n\n    if l2_beta > 0:\n        submission_name = 'l2{}-'.format(l2_beta) + submission_name\n\n    if keep_prob < 1:\n        submission_name = 'dk{}-'.format(keep_prob) + submission_name\n\n    if minibatch_size != num_examples:\n        submission_name = 'mb{}-'.format(minibatch_size) + submission_name\n\n    return submission_name\n\n\ndef plot_model_cost(train_costs, validation_costs, submission_name):\n    \"\"\"\n    :param train_costs: array with the costs from the model training\n    :param validation_costs: array with the costs from the model validation\n    :param submission_name: name of the submission (used for the plot title)\n    :return:\n    \"\"\"\n    plt.plot(np.squeeze(train_costs), label='Train cost')\n    plt.plot(np.squeeze(validation_costs), label='Validation cost')\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Model: \" + submission_name)\n    plt.legend()\n    plt.show()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "867e8eacabcf858711bafcaa51fbf67bb9b74851",
        "_cell_guid": "c28e3fdf-69d1-444f-85d6-72d8f112d9f9"
      },
      "cell_type": "markdown",
      "source": "### MODEL"
    },
    {
      "metadata": {
        "_uuid": "3f3f275f6a5cf860d80a579ac12d9659dee52dd4",
        "_cell_guid": "8b2052cb-a73e-4d3f-a039-e868ec963044",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "def model(train_set, train_labels, validation_set, validation_labels, layers_dims, learning_rate=0.01, num_epochs=1001,\n          print_cost=True, plot_cost=True, l2_beta=0., keep_prob=1.0, hidden_activation='relu', return_best=False,\n          minibatch_size=0, lr_decay=0):\n    \"\"\"\n    :param train_set: training set\n    :param train_labels: training labels\n    :param validation_set: validation set\n    :param validation_labels: validation labels\n    :param layers_dims: array with the layer for the model\n    :param learning_rate: learning rate of the optimization\n    :param num_epochs: number of epochs of the optimization loop\n    :param print_cost: True to print the cost every 500 epochs\n    :param plot_cost: True to plot the train and validation cost\n    :param l2_beta: beta parameter for the l2 regularization\n    :param keep_prob: probability to keep each node of each hidden layer (dropout)\n    :param hidden_activation: activation function to be used on the hidden layers\n    :param return_best: True to return the highest params from all epochs\n    :param minibatch_size: size of th mini batch\n    :param lr_decay: if != 0, sets de learning rate decay on each epoch\n    :return parameters: parameters learnt by the model. They can then be used to predict.\n    :return submission_name: name for the trained model\n    \"\"\"\n\n    ops.reset_default_graph()  # to be able to rerun the model without overwriting tf variables\n\n    input_size = layers_dims[0]\n    output_size = layers_dims[-1]\n    num_examples = train_set.shape[0]\n    n_layers = len(layers_dims)\n    train_costs = []\n    validation_costs = []\n    best_iteration = [float('inf'), 0]\n    best_params = None\n\n    if minibatch_size == 0 or minibatch_size > num_examples:\n        minibatch_size = num_examples\n\n    num_minibatches = num_examples // minibatch_size\n\n    if num_minibatches == 0:\n        num_minibatches = 1\n\n    submission_name = build_submission_name(layers_dims, num_epochs, lr_decay, learning_rate, l2_beta, keep_prob,\n                                            minibatch_size, num_examples)\n\n    x, y = create_placeholders(input_size, output_size)\n    tf_valid_dataset = tf.cast(tf.constant(validation_set), tf.float32)\n    parameters = initialize_parameters(layers_dims)\n\n    fw_output_train = forward_propagation(x, parameters, keep_prob, hidden_activation)\n    train_cost = compute_cost(fw_output_train, y)\n\n    fw_output_valid = forward_propagation(tf_valid_dataset, parameters, keep_prob, hidden_activation)\n    validation_cost = compute_cost(fw_output_valid, validation_labels)\n\n    if l2_beta > 0:\n        train_cost = l2_regularizer(train_cost, l2_beta, parameters, n_layers)\n        validation_cost = l2_regularizer(validation_cost, l2_beta, parameters, n_layers)\n\n    if lr_decay != 0:\n        global_step = tf.Variable(0, trainable=False)\n        learning_rate = tf.train.inverse_time_decay(learning_rate, global_step=global_step, decay_rate=lr_decay,\n                                                    decay_steps=1)\n        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(train_cost, global_step=global_step)\n    else:\n        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(train_cost)\n\n    init = tf.global_variables_initializer()\n\n    with tf.Session() as sess:\n        sess.run(init)\n\n        for epoch in range(num_epochs):\n            train_epoch_cost = 0.\n            validation_epoch_cost = 0.\n\n            minibatches = mini_batches(train_set, train_labels, minibatch_size)\n\n            for minibatch in minibatches:\n                (minibatch_X, minibatch_Y) = minibatch\n                feed_dict = {x: minibatch_X, y: minibatch_Y}\n\n                _, minibatch_train_cost, minibatch_validation_cost = sess.run(\n                    [optimizer, train_cost, validation_cost], feed_dict=feed_dict)\n\n                train_epoch_cost += minibatch_train_cost / num_minibatches\n                validation_epoch_cost += minibatch_validation_cost / num_minibatches\n\n            if print_cost is True and epoch % 500 == 0:\n                print(\"Train cost after epoch %i: %f\" % (epoch, train_epoch_cost))\n                print(\"Validation cost after epoch %i: %f\" % (epoch, validation_epoch_cost))\n\n            if plot_cost is True and epoch % 10 == 0:\n                train_costs.append(train_epoch_cost)\n                validation_costs.append(validation_epoch_cost)\n\n            if return_best is True and validation_epoch_cost < best_iteration[0]:\n                best_iteration[0] = validation_epoch_cost\n                best_iteration[1] = epoch\n                best_params = sess.run(parameters)\n\n        if return_best is True:\n            parameters = best_params\n        else:\n            parameters = sess.run(parameters)\n\n        print(\"Parameters have been trained, getting metrics...\")\n\n        train_rmse = rmse(predict(train_set, parameters), train_labels)\n        validation_rmse = rmse(predict(validation_set, parameters), validation_labels)\n        train_rmsle = rmsle(predict(train_set, parameters), train_labels)\n        validation_rmsle = rmsle(predict(validation_set, parameters), validation_labels)\n\n        print('Train rmse: {:.4f}'.format(train_rmse))\n        print('Validation rmse: {:.4f}'.format(validation_rmse))\n        print('Train rmsle: {:.4f}'.format(train_rmsle))\n        print('Validation rmsle: {:.4f}'.format(validation_rmsle))\n\n        submission_name = 'tr_cost-{:.2f}-vd_cost{:.2f}-'.format(train_rmse, validation_rmse) + submission_name\n\n        if return_best is True:\n            print('Lowest rmse: {:.2f} at epoch {}'.format(best_iteration[0], best_iteration[1]))\n\n        if plot_cost is True:\n            plot_model_cost(train_costs, validation_costs, submission_name)\n\n        return parameters, submission_name",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e09f3dec7634495cecf3ebf10d97e9026fecab2a",
        "_cell_guid": "59489594-c3b3-4726-959d-9700d6eab01b"
      },
      "cell_type": "markdown",
      "source": "### Load data"
    },
    {
      "metadata": {
        "_uuid": "d17fd06ff48989b8a590e107ab61dcafe9b5acaa",
        "_cell_guid": "e2f05348-2fc9-46ff-99bc-e8e9411707b5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "TRAIN_PATH = '../input/houseprices-log/train_cleaned.csv'\nTEST_PATH = '../input/houseprices-log/test_cleaned.csv'\n\ntrain, test = load_data(TRAIN_PATH, TEST_PATH)\n\n# get the labels values\ntrain_raw_labels = train['SalePrice'].to_frame().as_matrix()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "number of training examples = 1460\nnumber of test examples = 1459\ntrain shape: (1460, 48)\ntest shape: (1459, 47)\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  import sys\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "4f601881317ca1db93b3c130c3b472d08c118050"
      },
      "cell_type": "markdown",
      "source": "### Pre process data"
    },
    {
      "metadata": {
        "_uuid": "e6c464a0d8c6b7f914c6f4b51d078bdf2cb0c39c",
        "_cell_guid": "775ff346-2b93-4ec5-9ca4-bff789220d86",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# pre process data sets\ntrain_pre = pre_process_data(train)\ntest_pre = pre_process_data(test)\n\n# drop unwanted columns\ntrain_pre = train_pre.drop(['Id', 'SalePrice'], axis=1)\ntest_pre = test_pre.drop(['Id'], axis=1)\n\n# align both data sets (by outer join), to make they have the same amount of features,\n# this is required because of the mismatched categorical values in train and test sets\ntrain_pre, test_pre = train_pre.align(test_pre, join='outer', axis=1)\n\n# replace the nan values added by align for 0\ntrain_pre.replace(to_replace=np.nan, value=0, inplace=True)\ntest_pre.replace(to_replace=np.nan, value=0, inplace=True)\n\ntrain_pre = train_pre.as_matrix().astype(np.float)\ntest_pre = test_pre.as_matrix().astype(np.float)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1cf4c62d309b7009b369ca28ae36fbaf83c7fe20"
      },
      "cell_type": "markdown",
      "source": "### Normalize data"
    },
    {
      "metadata": {
        "_uuid": "7fe684fb86c5733fd06f0a4fbe97cc16a9e5a942",
        "_cell_guid": "ae8f5eda-877e-4ccc-9e23-abd3ee032da6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# scale values\nstandard_scaler = preprocessing.StandardScaler()\ntrain_pre = standard_scaler.fit_transform(train_pre)\ntest_pre = standard_scaler.fit_transform(test_pre)\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(train_pre, train_raw_labels, test_size=0.3, random_state=1)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4285232cdfd7670167d3ea873e77c3555c6cfda7"
      },
      "cell_type": "markdown",
      "source": "### Model parameters"
    },
    {
      "metadata": {
        "_uuid": "01acd7dbf464be0e63325450f3734cd8793040b6",
        "_cell_guid": "58ad99ea-34a0-4c13-9b9a-02d8259f74e6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# hyperparameters\ninput_size = train_pre.shape[1]\noutput_size = 1\nnum_epochs = 14001\nlearning_rate = 0.0001\nlayers_dims = [input_size, 512, 256, 64, output_size]",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f92bcfdf90732eec5f2766b13dec33fa8640915"
      },
      "cell_type": "markdown",
      "source": "### Train model"
    },
    {
      "metadata": {
        "_uuid": "639b2f204bdb9cdfaf3897e3e6a799c014a82198",
        "_cell_guid": "ce543556-7ebb-4a14-84b9-d86c65c5f9ad",
        "trusted": true
      },
      "cell_type": "code",
      "source": "parameters, submission_name = model(X_train, Y_train, X_valid, Y_valid, layers_dims, num_epochs=num_epochs,\n                                    learning_rate=learning_rate, print_cost=True, plot_cost=True, l2_beta=10,\n                                    keep_prob=0.7, minibatch_size=0, return_best=True)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train cost after epoch 0: 3565.748291\nValidation cost after epoch 0: 3565.670410\nTrain cost after epoch 500: 672.915710\nValidation cost after epoch 500: 672.898010\nTrain cost after epoch 1000: 109.199242\nValidation cost after epoch 1000: 109.174149\nTrain cost after epoch 1500: 25.126644\nValidation cost after epoch 1500: 25.099518\nTrain cost after epoch 2000: 14.130481\nValidation cost after epoch 2000: 14.101989\nTrain cost after epoch 2500: 12.356677\nValidation cost after epoch 2500: 12.331275\nTrain cost after epoch 3000: 11.871288\nValidation cost after epoch 3000: 11.845230\nTrain cost after epoch 3500: 11.635536\nValidation cost after epoch 3500: 11.605295\nTrain cost after epoch 4000: 11.483928\nValidation cost after epoch 4000: 11.457842\nTrain cost after epoch 4500: 11.360120\nValidation cost after epoch 4500: 11.331917\nTrain cost after epoch 5000: 11.242018\nValidation cost after epoch 5000: 11.209178\nTrain cost after epoch 5500: 11.105302\nValidation cost after epoch 5500: 11.083327\nTrain cost after epoch 6000: 10.955854\nValidation cost after epoch 6000: 10.913585\nTrain cost after epoch 6500: 10.763983\nValidation cost after epoch 6500: 10.759089\nTrain cost after epoch 7000: 10.531131\nValidation cost after epoch 7000: 10.499773\nTrain cost after epoch 7500: 10.224388\nValidation cost after epoch 7500: 10.185071\nTrain cost after epoch 8000: 9.735615\nValidation cost after epoch 8000: 9.720192\nTrain cost after epoch 8500: 8.777569\nValidation cost after epoch 8500: 8.757874\nTrain cost after epoch 9000: 8.104570\nValidation cost after epoch 9000: 8.109306\nTrain cost after epoch 9500: 7.580853\nValidation cost after epoch 9500: 7.619916\nTrain cost after epoch 10000: 7.256435\nValidation cost after epoch 10000: 7.219717\nTrain cost after epoch 10500: 6.922760\nValidation cost after epoch 10500: 6.910447\nTrain cost after epoch 11000: 6.668257\nValidation cost after epoch 11000: 6.615467\nTrain cost after epoch 11500: 6.264089\nValidation cost after epoch 11500: 6.299759\nTrain cost after epoch 12000: 6.064107\nValidation cost after epoch 12000: 5.986809\nTrain cost after epoch 12500: 5.835266\nValidation cost after epoch 12500: 5.876351\nTrain cost after epoch 13000: 5.601692\nValidation cost after epoch 13000: 5.626175\nTrain cost after epoch 13500: 5.396188\nValidation cost after epoch 13500: 5.323574\nTrain cost after epoch 14000: 5.240619\nValidation cost after epoch 14000: 5.215782\nParameters have been trained, getting metrics...\nTrain rmse: 0.9361\nValidation rmse: 0.9331\nTrain rmsle: 0.0735\nValidation rmsle: 0.0732\nLowest rmse: 5.09 at epoch 13973\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "81f21a7ac28ec33af50f46e0e40ea845a0401e78"
      },
      "cell_type": "markdown",
      "source": "### Make predictions"
    },
    {
      "metadata": {
        "_uuid": "520356c9b6a40bf3b4e3c3701ceb6e861b4f41dc",
        "_cell_guid": "97efe509-bbe8-4452-b7eb-9f8128e705d3",
        "trusted": true
      },
      "cell_type": "code",
      "source": "prediction = list(map(lambda val: float(val), predict(test_pre, parameters)))\nprediction = list(map(lambda val: np.expm1(val), prediction))",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fc5374700f553cdb789b70676bc88c2fe50c9e1"
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame({\"Id\":test.Id.values})\nsubmission[\"SalePrice\"] = prediction\nsubmission.to_csv(\"submission.csv\", index=False)",
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}