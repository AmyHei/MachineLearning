{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework will use dataset Amazon Employee Access Challenge from [Kaggle](https://www.kaggle.com) competition for our experiments. Data can be downloaded [here](https://www.kaggle.com/c/amazon-employee-access-challenge/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of this tutorial you need to provide a tsv file with answers.\n",
    "There are 17 questions in this tutorial. The resulting tsv file should consist of 17 lines, each line should contain the number of the question, an answer to it and a tab separater between them. Questions are numbered from 1 to 17.\n",
    "See an example of the resulting file here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to install the libraries. To do that run:\n",
    "\n",
    "`pip install catboost\n",
    " pip install shap\n",
    " pip install ipywidgets\n",
    " jupyter nbextension enable --py widgetsnbextension`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pandas>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from catboost)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from catboost)\n",
      "Requirement already satisfied: enum34 in /opt/conda/lib/python3.6/site-packages (from catboost)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from catboost)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.19.1->catboost)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas>=0.19.1->catboost)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install catboost\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!{sys.executable} -m jupyter nbextension enable --py widgetsnbextension\n",
    "# !{sys.executable} -m pip install shap # ERROR can't install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first download the data and put it to folder `amazon`. Now we will read this data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import catboost\n",
    "from catboost import datasets\n",
    "from catboost import *\n",
    "\n",
    "from grader import Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = catboost.datasets.amazon()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../train.csv')\n",
    "test_df.to_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = Grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label values extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.ACTION\n",
    "X = train_df.drop('ACTION', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical features declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it makes sense to ananyze the dataset.\n",
    "First you need to calculate how many positive and negative objects are present in the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:**\n",
    "\n",
    "How many negative objects are present in the train dataset X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task negative_samples is: 0\n"
     ]
    }
   ],
   "source": [
    "zero_count = len(train_df[(train_df.ACTION < 0) | (train_df.RESOURCE < 0) | (train_df.MGR_ID < 0) |\n",
    "                          (train_df.ROLE_ROLLUP_1 < 0) | (train_df.ROLE_ROLLUP_2 < 0) | (train_df.ROLE_DEPTNAME < 0) | \n",
    "                          (train_df.ROLE_TITLE < 0) | (train_df.ROLE_FAMILY_DESC < 0) | (train_df.ROLE_FAMILY < 0) | \n",
    "                          (train_df.ROLE_CODE < 0)])\n",
    "grader.submit_tag('negative_samples', zero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**\n",
    "\n",
    "How many positive objects are present in the train dataset X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task positive_samples is: 32769\n"
     ]
    }
   ],
   "source": [
    "one_count = len(train_df[(train_df.ACTION > 0) | (train_df.RESOURCE > 0) | (train_df.MGR_ID > 0) |\n",
    "                          (train_df.ROLE_ROLLUP_1 > 0) | (train_df.ROLE_ROLLUP_2 > 0) | (train_df.ROLE_DEPTNAME > 0) | \n",
    "                          (train_df.ROLE_TITLE > 0) | (train_df.ROLE_FAMILY_DESC > 0) | (train_df.ROLE_FAMILY > 0) | \n",
    "                          (train_df.ROLE_CODE > 0)])\n",
    "grader.submit_tag('positive_samples', one_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero count = 0, One count = 32769\n"
     ]
    }
   ],
   "source": [
    "print('Zero count = ' + str(zero_count) + ', One count = ' + str(one_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for every feature you need to calculate number of unique values of this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:**\n",
    "    \n",
    "How many unique values has feature RESOURCE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task resource_unique_values is: 7518\n"
     ]
    }
   ],
   "source": [
    "unique_vals_for_RESOURCE = train_df['RESOURCE'].nunique()\n",
    "grader.submit_tag('resource_unique_values', unique_vals_for_RESOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a Pool object. This type is used for datasets in CatBoost. You can also use numpy array or dataframe. Working with Pool class is the most efficient way in terms of memory and speed. We recommend to create Pool from file in case if you have your data on disk or from FeaturesData if you use numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape\n",
      "dataset 1:(32769, 9)\n",
      "dataset 2:(32769, 10)\n",
      "dataset 3:(32769, 9)\n",
      "\n",
      "\n",
      "Column names\n",
      "dataset 1: \n",
      "['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
      "\n",
      "dataset 2:\n",
      "['ACTION', 'RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
      "\n",
      "dataset 3:\n",
      "['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from catboost import Pool\n",
    "\n",
    "pool1 = Pool(data=X, label=y, cat_features=cat_features)\n",
    "pool2 = Pool(data='../train.csv', delimiter=',', has_header=True)\n",
    "pool3 = Pool(data=X, cat_features=cat_features)\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 1:' + str(pool1.shape) + '\\ndataset 2:' + str(pool2.shape)  + '\\ndataset 3:' + str(pool3.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('dataset 1: ')\n",
    "print(pool1.get_feature_names()) \n",
    "print('\\ndataset 2:')\n",
    "print(pool2.get_feature_names())\n",
    "print('\\ndataset 3:')\n",
    "print(pool3.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split your data into train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you will be training your model, you will have to detect overfitting and select best parameters. To do that you need to have a validation dataset.\n",
    "Normally you would be using some random split, for example\n",
    "`train_test_split` from `sklearn.model_selection`.\n",
    "But for the purpose of this homework the train part will be the first 80% of the data and the evaluation part will be the last 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X.iloc[:train_count,:]\n",
    "y_train = y[:train_count]\n",
    "X_validation = X.iloc[train_count:, :]\n",
    "y_validation = y[train_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is fitted: True\n",
      "Model params:\n",
      "{'random_seed': 0, 'loss_function': 'Logloss', 'learning_rate': 0.1, 'iterations': 5}\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=5,\n",
    "    random_seed=0,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    logging_level='Silent'\n",
    ")\n",
    "print('Model is fitted: ' + str(model.is_fitted()))\n",
    "print('Model params:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdout of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in stdout values of the loss function on each iteration, or on each k-th iteration.\n",
    "You can also see how much time passed since the start of the training and how much time is left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3007996\ttest: 0.3044268\tbest: 0.3044268 (0)\ttotal: 62ms\tremaining: 867ms\n",
      "3:\tlearn: 0.1800237\ttest: 0.1674121\tbest: 0.1674121 (3)\ttotal: 546ms\tremaining: 1.5s\n",
      "6:\tlearn: 0.1706950\ttest: 0.1549520\tbest: 0.1549520 (6)\ttotal: 917ms\tremaining: 1.05s\n",
      "9:\tlearn: 0.1672391\ttest: 0.1495040\tbest: 0.1495040 (9)\ttotal: 1.23s\tremaining: 614ms\n",
      "12:\tlearn: 0.1645499\ttest: 0.1487789\tbest: 0.1487789 (12)\ttotal: 1.64s\tremaining: 252ms\n",
      "14:\tlearn: 0.1630092\ttest: 0.1469375\tbest: 0.1469375 (14)\ttotal: 1.94s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1469374586\n",
      "bestIteration = 14\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee1f57860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=15,\n",
    "    verbose=3\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't specify random_seed then random seed will be set to a new value each time.\n",
    "After the training has finished you can look on the value of the random seed that was set.\n",
    "If you train again with this random_seed, you will get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3007996\ttest: 0.3044268\tbest: 0.3044268 (0)\ttotal: 55.5ms\tremaining: 222ms\n",
      "1:\tlearn: 0.2161146\ttest: 0.2152075\tbest: 0.2152075 (1)\ttotal: 208ms\tremaining: 312ms\n",
      "2:\tlearn: 0.1879597\ttest: 0.1797290\tbest: 0.1797290 (2)\ttotal: 348ms\tremaining: 232ms\n",
      "3:\tlearn: 0.1800237\ttest: 0.1674121\tbest: 0.1674121 (3)\ttotal: 492ms\tremaining: 123ms\n",
      "4:\tlearn: 0.1732668\ttest: 0.1581682\tbest: 0.1581682 (4)\ttotal: 649ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1581682309\n",
      "bestIteration = 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee1f57518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=5\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used random seed = 0\n",
      "0:\tlearn: 0.3007996\ttest: 0.3044268\tbest: 0.3044268 (0)\ttotal: 55.3ms\tremaining: 221ms\n",
      "1:\tlearn: 0.2161146\ttest: 0.2152075\tbest: 0.2152075 (1)\ttotal: 211ms\tremaining: 317ms\n",
      "2:\tlearn: 0.1879597\ttest: 0.1797290\tbest: 0.1797290 (2)\ttotal: 315ms\tremaining: 210ms\n",
      "3:\tlearn: 0.1800237\ttest: 0.1674121\tbest: 0.1674121 (3)\ttotal: 452ms\tremaining: 113ms\n",
      "4:\tlearn: 0.1732668\ttest: 0.1581682\tbest: 0.1581682 (4)\ttotal: 618ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1581682309\n",
      "bestIteration = 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5f1777bac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = model.random_seed_\n",
    "print('Used random seed = ' + str(random_seed))\n",
    "model = CatBoostClassifier(\n",
    "    iterations=5,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try training 10 models with parameters and calculate mean and the standart deviation of Logloss error on validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:**\n",
    "\n",
    "What is the mean value of the Logloss metric on validation dataset (X_validation, y_validation) after 10 times training `CatBoostClassifier` with different random seeds in the following way:\n",
    "\n",
    "`model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    learning_rate=0.1,\n",
    "    random_seed={my_random_seed}\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used random seed = 0\n",
      "0:\tlearn: 0.5790122\ttest: 0.5797377\tbest: 0.5797377 (0)\ttotal: 77.5ms\tremaining: 23.2s\n",
      "50:\tlearn: 0.1606281\ttest: 0.1432391\tbest: 0.1432391 (50)\ttotal: 6.86s\tremaining: 33.5s\n",
      "100:\tlearn: 0.1555506\ttest: 0.1394226\tbest: 0.1394226 (100)\ttotal: 12.9s\tremaining: 25.5s\n",
      "150:\tlearn: 0.1515049\ttest: 0.1384309\tbest: 0.1384019 (148)\ttotal: 20.3s\tremaining: 20.1s\n",
      "200:\tlearn: 0.1486424\ttest: 0.1381162\tbest: 0.1381162 (200)\ttotal: 27.7s\tremaining: 13.6s\n",
      "250:\tlearn: 0.1467162\ttest: 0.1379267\tbest: 0.1379267 (250)\ttotal: 35.2s\tremaining: 6.88s\n",
      "299:\tlearn: 0.1452004\ttest: 0.1379528\tbest: 0.1377092 (262)\ttotal: 42.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1377092211\n",
      "bestIteration = 262\n",
      "\n",
      "Shrink model to first 263 iterations.\n",
      "Used random seed = 1\n",
      "0:\tlearn: 0.5785828\ttest: 0.5796621\tbest: 0.5796621 (0)\ttotal: 109ms\tremaining: 32.7s\n",
      "50:\tlearn: 0.1617489\ttest: 0.1457523\tbest: 0.1457523 (50)\ttotal: 6.63s\tremaining: 32.4s\n",
      "100:\tlearn: 0.1542598\ttest: 0.1402208\tbest: 0.1401744 (97)\ttotal: 13.4s\tremaining: 26.4s\n",
      "150:\tlearn: 0.1509185\ttest: 0.1397559\tbest: 0.1396483 (143)\ttotal: 20.6s\tremaining: 20.3s\n",
      "200:\tlearn: 0.1476642\ttest: 0.1391333\tbest: 0.1390896 (197)\ttotal: 28.1s\tremaining: 13.9s\n",
      "250:\tlearn: 0.1458554\ttest: 0.1394880\tbest: 0.1390896 (197)\ttotal: 35.7s\tremaining: 6.97s\n",
      "299:\tlearn: 0.1441857\ttest: 0.1394407\tbest: 0.1390896 (197)\ttotal: 43.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1390896115\n",
      "bestIteration = 197\n",
      "\n",
      "Shrink model to first 198 iterations.\n",
      "Used random seed = 2\n",
      "0:\tlearn: 0.5763417\ttest: 0.5764993\tbest: 0.5764993 (0)\ttotal: 128ms\tremaining: 38.4s\n",
      "50:\tlearn: 0.1601817\ttest: 0.1432422\tbest: 0.1432422 (50)\ttotal: 6.74s\tremaining: 32.9s\n",
      "100:\tlearn: 0.1551444\ttest: 0.1401669\tbest: 0.1401469 (93)\ttotal: 13.7s\tremaining: 27s\n",
      "150:\tlearn: 0.1514471\ttest: 0.1395191\tbest: 0.1394717 (148)\ttotal: 21.6s\tremaining: 21.4s\n",
      "200:\tlearn: 0.1485357\ttest: 0.1394829\tbest: 0.1393539 (167)\ttotal: 29.6s\tremaining: 14.6s\n",
      "250:\tlearn: 0.1461326\ttest: 0.1391988\tbest: 0.1390539 (234)\ttotal: 37.2s\tremaining: 7.27s\n",
      "299:\tlearn: 0.1444763\ttest: 0.1390655\tbest: 0.1389049 (277)\ttotal: 44.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1389049488\n",
      "bestIteration = 277\n",
      "\n",
      "Shrink model to first 278 iterations.\n",
      "Used random seed = 3\n",
      "0:\tlearn: 0.5777218\ttest: 0.5783576\tbest: 0.5783576 (0)\ttotal: 114ms\tremaining: 34.1s\n",
      "50:\tlearn: 0.1616912\ttest: 0.1452233\tbest: 0.1452233 (50)\ttotal: 6.66s\tremaining: 32.5s\n",
      "100:\tlearn: 0.1544263\ttest: 0.1388443\tbest: 0.1388443 (100)\ttotal: 13.4s\tremaining: 26.5s\n",
      "150:\tlearn: 0.1514526\ttest: 0.1383686\tbest: 0.1383324 (149)\ttotal: 20.8s\tremaining: 20.6s\n",
      "200:\tlearn: 0.1476871\ttest: 0.1374769\tbest: 0.1371881 (177)\ttotal: 28.9s\tremaining: 14.2s\n",
      "250:\tlearn: 0.1460306\ttest: 0.1373020\tbest: 0.1371881 (177)\ttotal: 36.7s\tremaining: 7.16s\n",
      "299:\tlearn: 0.1449045\ttest: 0.1376526\tbest: 0.1371881 (177)\ttotal: 44.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1371880812\n",
      "bestIteration = 177\n",
      "\n",
      "Shrink model to first 178 iterations.\n",
      "Used random seed = 4\n",
      "0:\tlearn: 0.5777959\ttest: 0.5778124\tbest: 0.5778124 (0)\ttotal: 149ms\tremaining: 44.5s\n",
      "50:\tlearn: 0.1618128\ttest: 0.1446827\tbest: 0.1446827 (50)\ttotal: 6.64s\tremaining: 32.4s\n",
      "100:\tlearn: 0.1558255\ttest: 0.1403200\tbest: 0.1402608 (95)\ttotal: 12.9s\tremaining: 25.4s\n",
      "150:\tlearn: 0.1525251\ttest: 0.1400111\tbest: 0.1398339 (142)\ttotal: 20.1s\tremaining: 19.9s\n",
      "200:\tlearn: 0.1505529\ttest: 0.1400779\tbest: 0.1398339 (142)\ttotal: 27.8s\tremaining: 13.7s\n",
      "250:\tlearn: 0.1481755\ttest: 0.1402626\tbest: 0.1396911 (212)\ttotal: 35.3s\tremaining: 6.9s\n",
      "299:\tlearn: 0.1464591\ttest: 0.1401187\tbest: 0.1396911 (212)\ttotal: 43.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1396911053\n",
      "bestIteration = 212\n",
      "\n",
      "Shrink model to first 213 iterations.\n",
      "Used random seed = 5\n",
      "0:\tlearn: 0.5788212\ttest: 0.5799392\tbest: 0.5799392 (0)\ttotal: 105ms\tremaining: 31.3s\n",
      "50:\tlearn: 0.1604410\ttest: 0.1451458\tbest: 0.1451458 (50)\ttotal: 6.46s\tremaining: 31.5s\n",
      "100:\tlearn: 0.1550335\ttest: 0.1410974\tbest: 0.1410974 (100)\ttotal: 12.9s\tremaining: 25.5s\n",
      "150:\tlearn: 0.1507740\ttest: 0.1394203\tbest: 0.1393951 (146)\ttotal: 20.3s\tremaining: 20s\n",
      "200:\tlearn: 0.1480950\ttest: 0.1386970\tbest: 0.1386970 (200)\ttotal: 27.9s\tremaining: 13.7s\n",
      "250:\tlearn: 0.1458907\ttest: 0.1383342\tbest: 0.1382407 (230)\ttotal: 35.4s\tremaining: 6.9s\n",
      "299:\tlearn: 0.1442766\ttest: 0.1380951\tbest: 0.1380292 (279)\ttotal: 42.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1380291947\n",
      "bestIteration = 279\n",
      "\n",
      "Shrink model to first 280 iterations.\n",
      "Used random seed = 6\n",
      "0:\tlearn: 0.5778379\ttest: 0.5779979\tbest: 0.5779979 (0)\ttotal: 150ms\tremaining: 45s\n",
      "50:\tlearn: 0.1612183\ttest: 0.1440793\tbest: 0.1440793 (50)\ttotal: 6.6s\tremaining: 32.2s\n",
      "100:\tlearn: 0.1540824\ttest: 0.1387695\tbest: 0.1387134 (96)\ttotal: 13.2s\tremaining: 26.1s\n",
      "150:\tlearn: 0.1502745\ttest: 0.1375958\tbest: 0.1375393 (145)\ttotal: 20.5s\tremaining: 20.3s\n",
      "200:\tlearn: 0.1475584\ttest: 0.1372812\tbest: 0.1372052 (193)\ttotal: 28.2s\tremaining: 13.9s\n",
      "250:\tlearn: 0.1456805\ttest: 0.1371861\tbest: 0.1371346 (241)\ttotal: 36.1s\tremaining: 7.04s\n",
      "299:\tlearn: 0.1442303\ttest: 0.1375012\tbest: 0.1371346 (241)\ttotal: 43.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1371345869\n",
      "bestIteration = 241\n",
      "\n",
      "Shrink model to first 242 iterations.\n",
      "Used random seed = 7\n",
      "0:\tlearn: 0.5790122\ttest: 0.5797377\tbest: 0.5797377 (0)\ttotal: 93.7ms\tremaining: 28s\n",
      "50:\tlearn: 0.1613167\ttest: 0.1454845\tbest: 0.1454845 (50)\ttotal: 6.68s\tremaining: 32.6s\n",
      "100:\tlearn: 0.1558111\ttest: 0.1407022\tbest: 0.1407022 (100)\ttotal: 13.2s\tremaining: 25.9s\n",
      "150:\tlearn: 0.1506563\ttest: 0.1385987\tbest: 0.1385494 (148)\ttotal: 20.7s\tremaining: 20.4s\n",
      "200:\tlearn: 0.1475763\ttest: 0.1382478\tbest: 0.1380578 (192)\ttotal: 28.4s\tremaining: 14s\n",
      "250:\tlearn: 0.1456677\ttest: 0.1383706\tbest: 0.1380120 (219)\ttotal: 36s\tremaining: 7.03s\n",
      "299:\tlearn: 0.1437891\ttest: 0.1383775\tbest: 0.1380120 (219)\ttotal: 43.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.138011952\n",
      "bestIteration = 219\n",
      "\n",
      "Shrink model to first 220 iterations.\n",
      "Used random seed = 8\n",
      "0:\tlearn: 0.5790122\ttest: 0.5797377\tbest: 0.5797377 (0)\ttotal: 83.4ms\tremaining: 24.9s\n",
      "50:\tlearn: 0.1613498\ttest: 0.1458987\tbest: 0.1458987 (50)\ttotal: 6.63s\tremaining: 32.4s\n",
      "100:\tlearn: 0.1544311\ttest: 0.1405741\tbest: 0.1405584 (98)\ttotal: 13s\tremaining: 25.6s\n",
      "150:\tlearn: 0.1503428\ttest: 0.1390345\tbest: 0.1389588 (146)\ttotal: 20.3s\tremaining: 20s\n",
      "200:\tlearn: 0.1467899\ttest: 0.1383347\tbest: 0.1382993 (199)\ttotal: 27.9s\tremaining: 13.7s\n",
      "250:\tlearn: 0.1450715\ttest: 0.1382363\tbest: 0.1381130 (212)\ttotal: 35.8s\tremaining: 6.98s\n",
      "299:\tlearn: 0.1435473\ttest: 0.1383286\tbest: 0.1381130 (212)\ttotal: 43.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1381130381\n",
      "bestIteration = 212\n",
      "\n",
      "Shrink model to first 213 iterations.\n",
      "Used random seed = 9\n",
      "0:\tlearn: 0.5763526\ttest: 0.5771323\tbest: 0.5771323 (0)\ttotal: 111ms\tremaining: 33.1s\n",
      "50:\tlearn: 0.1616638\ttest: 0.1439080\tbest: 0.1439080 (50)\ttotal: 6.8s\tremaining: 33.2s\n",
      "100:\tlearn: 0.1559343\ttest: 0.1396163\tbest: 0.1395966 (99)\ttotal: 13.4s\tremaining: 26.4s\n",
      "150:\tlearn: 0.1517975\ttest: 0.1386301\tbest: 0.1384641 (146)\ttotal: 21.1s\tremaining: 20.8s\n",
      "200:\tlearn: 0.1498110\ttest: 0.1385336\tbest: 0.1384641 (146)\ttotal: 28.8s\tremaining: 14.2s\n",
      "250:\tlearn: 0.1477430\ttest: 0.1382561\tbest: 0.1381517 (246)\ttotal: 36.9s\tremaining: 7.2s\n",
      "299:\tlearn: 0.1462467\ttest: 0.1380096\tbest: 0.1379367 (286)\ttotal: 45.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1379367316\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for random_seed in range(10):\n",
    "    print('Used random seed = ' + str(random_seed))\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.1,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features=cat_features,\n",
    "        eval_set=(X_validation, y_validation),\n",
    "        verbose=50\n",
    "    )\n",
    "    metrics.append(model.get_best_score()['validation_0']['Logloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task logloss_mean is: 0.138180847126\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "metrics = numpy.array(metrics)\n",
    "mean = numpy.mean(metrics, axis=0)\n",
    "grader.submit_tag('logloss_mean', mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:**\n",
    "\n",
    "What is the standard deviation of it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task logloss_std is: 0.000777781825619\n"
     ]
    }
   ],
   "source": [
    "stddev = (numpy.std(metrics, axis=0))\n",
    "grader.submit_tag('logloss_std', stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics calculation and graph plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When experimenting with Jupyter notebook you can see graphs of different errors during training.\n",
    "To do that you need to use `plot=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e6a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.1,\n",
    "    custom_loss=['Accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    logging_level='Silent',\n",
    "#     plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:**\n",
    "\n",
    "What is the value of the accuracy metric value on evaluation dataset after training with parameters `iterations=50`, `random_seed=63`, `learning_rate=0.1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task accuracy_6 is: 0\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "grader.submit_tag('accuracy_6', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3007996\ttest: 0.3044268\tbest: 0.3044268 (0)\ttotal: 66.9ms\tremaining: 1m 6s\n",
      "100:\tlearn: 0.1416460\ttest: 0.1404156\tbest: 0.1402309 (96)\ttotal: 16s\tremaining: 2m 22s\n",
      "200:\tlearn: 0.1340506\ttest: 0.1447274\tbest: 0.1399893 (106)\ttotal: 32.3s\tremaining: 2m 8s\n",
      "300:\tlearn: 0.1281182\ttest: 0.1478018\tbest: 0.1399893 (106)\ttotal: 47.4s\tremaining: 1m 50s\n",
      "400:\tlearn: 0.1213678\ttest: 0.1506548\tbest: 0.1399893 (106)\ttotal: 1m 3s\tremaining: 1m 34s\n",
      "500:\tlearn: 0.1178627\ttest: 0.1527704\tbest: 0.1399893 (106)\ttotal: 1m 17s\tremaining: 1m 17s\n",
      "600:\tlearn: 0.1145490\ttest: 0.1531613\tbest: 0.1399893 (106)\ttotal: 1m 33s\tremaining: 1m 1s\n",
      "700:\tlearn: 0.1121429\ttest: 0.1548145\tbest: 0.1399893 (106)\ttotal: 1m 48s\tremaining: 46.1s\n",
      "800:\tlearn: 0.1087987\ttest: 0.1576137\tbest: 0.1399893 (106)\ttotal: 2m 3s\tremaining: 30.6s\n",
      "900:\tlearn: 0.1064078\ttest: 0.1590852\tbest: 0.1399893 (106)\ttotal: 2m 18s\tremaining: 15.2s\n",
      "999:\tlearn: 0.1037092\ttest: 0.1610907\tbest: 0.1399893 (106)\ttotal: 2m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.139989279\n",
      "bestIteration = 106\n",
      "\n",
      "Shrink model to first 107 iterations.\n",
      "0:\tlearn: 0.6336452\ttest: 0.6340079\tbest: 0.6340079 (0)\ttotal: 70.7ms\tremaining: 1m 10s\n",
      "100:\tlearn: 0.1611479\ttest: 0.1449584\tbest: 0.1449584 (100)\ttotal: 13.1s\tremaining: 1m 56s\n",
      "200:\tlearn: 0.1557547\ttest: 0.1406980\tbest: 0.1406980 (200)\ttotal: 26.5s\tremaining: 1m 45s\n",
      "300:\tlearn: 0.1518685\ttest: 0.1396363\tbest: 0.1396363 (300)\ttotal: 42s\tremaining: 1m 37s\n",
      "400:\tlearn: 0.1491027\ttest: 0.1391260\tbest: 0.1390534 (387)\ttotal: 57.4s\tremaining: 1m 25s\n",
      "500:\tlearn: 0.1473104\ttest: 0.1388463\tbest: 0.1388368 (498)\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "600:\tlearn: 0.1458467\ttest: 0.1386551\tbest: 0.1386309 (598)\ttotal: 1m 28s\tremaining: 58.4s\n",
      "700:\tlearn: 0.1447626\ttest: 0.1385421\tbest: 0.1385153 (655)\ttotal: 1m 43s\tremaining: 44.2s\n",
      "800:\tlearn: 0.1434967\ttest: 0.1385943\tbest: 0.1384693 (758)\ttotal: 1m 59s\tremaining: 29.7s\n",
      "900:\tlearn: 0.1423225\ttest: 0.1386244\tbest: 0.1384693 (758)\ttotal: 2m 15s\tremaining: 14.9s\n",
      "999:\tlearn: 0.1411414\ttest: 0.1384660\tbest: 0.1384609 (998)\ttotal: 2m 32s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1384608761\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e0f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = CatBoostClassifier(\n",
    "    learning_rate=0.5,\n",
    "    iterations=1000,\n",
    "    random_seed=64,\n",
    "    train_dir='learning_rate_0.5',\n",
    "    custom_loss = ['Accuracy']\n",
    ")\n",
    "\n",
    "model2 = CatBoostClassifier(\n",
    "    learning_rate=0.05,\n",
    "    iterations=1000,\n",
    "    random_seed=64,\n",
    "    train_dir='learning_rate_0.05',\n",
    "    custom_loss = ['Accuracy']\n",
    ")\n",
    "model1.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=100\n",
    ")\n",
    "model2.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import MetricVisualizer\n",
    "# MetricVisualizer(['learning_rate_0.05', 'learning_rate_0.5']).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:**\n",
    "\n",
    "Try training these models for 1000 iterations. Which model will give better best resulting Accuracy on validation dataset?\n",
    "By best resulting accuracy we mean accuracy on best iteration, which might be not the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task best_model_name is: learning_rate_0.05\n"
     ]
    }
   ],
   "source": [
    "best_model_name = 'learning_rate_0.05'\n",
    "grader.submit_tag('best_model_name', best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a validation dataset is present then after training, the model is shrinked to a number of trees when it got best evaluation metric value on validation dataset.\n",
    "By default evaluation metric is the optimized metric. But you can set evaluation metric to some other metric.\n",
    "In the example below evaluation metric is `Accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee1f57cf8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    eval_metric='Accuracy'\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    logging_level='Silent',\n",
    "#     plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree count: 72\n"
     ]
    }
   ],
   "source": [
    "print('Tree count: ' + str(model.tree_count_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want the model to be shrinked, you can set `use_best_model=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee1f57eb8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    eval_metric='Accuracy',\n",
    "    use_best_model=False\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    logging_level='Silent',\n",
    "#     plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:**\n",
    "    \n",
    "What will be the number of trees in the resulting model after training with validation dataset with parameters `iterations=100`, ` learning_rate=0.5`, `eval_metric='Accuracy'` and with parameter `use_best_model=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task num_trees is: 100\n"
     ]
    }
   ],
   "source": [
    "tree_count = model.tree_count_\n",
    "grader.submit_tag('num_trees', tree_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next functionality you need to know about is cross-validation.\n",
    "For unbalanced datasets stratified cross-validation can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import cv\n",
    "\n",
    "params = {}\n",
    "params['loss_function'] = 'Logloss'\n",
    "params['iterations'] = 80\n",
    "params['custom_loss'] = 'AUC'\n",
    "params['random_seed'] = 63\n",
    "params['learning_rate'] = 0.5\n",
    "\n",
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y, cat_features=cat_features),\n",
    "    fold_count=5,\n",
    "    inverted=False,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "#     plot=True,\n",
    "    stratified=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation returns specified metric values on every iteration (or every k-th iteration, if you specify so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test-AUC-mean  test-AUC-std  test-Logloss-mean  test-Logloss-std  \\\n",
      "0       0.500000      0.000000           0.302197          0.000080   \n",
      "1       0.625621      0.122336           0.222651          0.014472   \n",
      "2       0.799508      0.012871           0.179930          0.004739   \n",
      "3       0.824558      0.013151           0.165090          0.003799   \n",
      "\n",
      "   train-AUC-mean  train-AUC-std  train-Logloss-mean  train-Logloss-std  \n",
      "0        0.499984       0.000017            0.302203           0.000050  \n",
      "1        0.614679       0.109875            0.225825           0.010991  \n",
      "2        0.758325       0.022924            0.190024           0.004146  \n",
      "3        0.781285       0.017559            0.178807           0.003176  \n"
     ]
    }
   ],
   "source": [
    "print(cv_data[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look on mean value and standard deviation of Logloss for cv on best iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation Logloss score, not stratified: 0.1409±0.0056 on step 65\n"
     ]
    }
   ],
   "source": [
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "\n",
    "print('Best validation Logloss score, not stratified: {:.4f}±{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:**\n",
    "\n",
    "Try running stratified cross-validation with the same parameters. What will be mean of Logloss metric on test of the stratified cross-validation on the best iteration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task mean_logloss_cv is: 0.140862080899\n"
     ]
    }
   ],
   "source": [
    "mean_on_best_iteration = np.min(cv_data['test-Logloss-mean'])\n",
    "grader.submit_tag('mean_logloss_cv', mean_on_best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10:**\n",
    "\n",
    "Try running stratified cross-validation with the same parameters. What will be the standard deviation of Logloss metric of the stratified cross-validation on the best iteration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task logloss_std_1 is: 7.97814926363e-05\n"
     ]
    }
   ],
   "source": [
    "std_on_best_iteration = np.min(cv_data['test-Logloss-std'])\n",
    "grader.submit_tag('logloss_std_1', std_on_best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful feature of the library is overfitting detector.\n",
    "Let's try training the model with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e320>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_early_stop = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    od_type='Iter',\n",
    "    od_wait=20,\n",
    "    eval_metric = 'AUC'\n",
    ")\n",
    "model_with_early_stop.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    logging_level='Silent',\n",
    "#     plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11:**\n",
    "\n",
    "Now try training the model with the same parameters and with overfitting detector, but with `eval_metric='AUC'`\n",
    "What will be the number of iterations after which the training will stop?\n",
    "(Not the number of trees in the resulting model, but the number of iterations that the algorithm will perform before training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task iterations_overfitting is: 100\n"
     ]
    }
   ],
   "source": [
    "iterations_count = model.get_params()['iterations']\n",
    "grader.submit_tag('iterations_overfitting', iterations_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you train for long time, for example for several hours, you need to save snapshots.\n",
    "Otherwise if your laptop or your server will reboot, you will loose all the progress.\n",
    "To do that you need to specify `snapshot_file` parameter.\n",
    "Try running the code below and interrupting the kernel after short time.\n",
    "Then try running the same cell again.\n",
    "The training will start from the iteration when the training was interrupted.\n",
    "Note that all additional files are written by default into `catboost_info` directory. It can be changed using `train_dir` parameter. So the snapshot file will be there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.1429637809\n",
      "bestIteration = 39\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e8d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=40,\n",
    "    save_snapshot=True,\n",
    "    snapshot_file='snapshot.bkp',\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    logging_level='Verbose'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to do predictions.\n",
    "The easiest one is to call predict or predict_proba.\n",
    "You also can make predictions using C++ code. For that see [documentation](https://tech.yandex.com/catboost/doc/dg/concepts/c-plus-plus-api-docpage/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0159  0.9841]\n",
      " [ 0.0157  0.9843]\n",
      " [ 0.0059  0.9941]\n",
      " ..., \n",
      " [ 0.0071  0.9929]\n",
      " [ 0.3818  0.6182]\n",
      " [ 0.0263  0.9737]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_proba(data=X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(data=X_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary classification resulting value is not necessary a value in `[0,1]`. It is some numeric value. To get the probability out of this value you need to calculate sigmoid of that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.1255  4.1387  5.122  ...,  4.9439  0.4819  3.6114]\n"
     ]
    }
   ],
   "source": [
    "raw_pred = model.predict(data=X_validation, prediction_type='RawFormulaVal')\n",
    "print(raw_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9841  0.9843  0.9941 ...,  0.9929  0.6182  0.9737]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "probabilities = [sigmoid(x) for x in raw_pred]\n",
    "print(np.array(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staged prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost also supports staged prediction - when you want to have a prediction on each object on each iteration (or on each k-th iteration). This can be used if you want to calculate the values of some custom metric using the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, predictions:\n",
      "[[ 0.228  0.772]\n",
      " [ 0.228  0.772]\n",
      " [ 0.228  0.772]\n",
      " ..., \n",
      " [ 0.228  0.772]\n",
      " [ 0.228  0.772]\n",
      " [ 0.228  0.772]]\n",
      "Iteration 1, predictions:\n",
      "[[ 0.1121  0.8879]\n",
      " [ 0.1273  0.8727]\n",
      " [ 0.1121  0.8879]\n",
      " ..., \n",
      " [ 0.1121  0.8879]\n",
      " [ 0.221   0.779 ]\n",
      " [ 0.1526  0.8474]]\n",
      "Iteration 2, predictions:\n",
      "[[ 0.0599  0.9401]\n",
      " [ 0.0686  0.9314]\n",
      " [ 0.0599  0.9401]\n",
      " ..., \n",
      " [ 0.0599  0.9401]\n",
      " [ 0.3378  0.6622]\n",
      " [ 0.0833  0.9167]]\n",
      "Iteration 3, predictions:\n",
      "[[ 0.0424  0.9576]\n",
      " [ 0.0486  0.9514]\n",
      " [ 0.0424  0.9576]\n",
      " ..., \n",
      " [ 0.0424  0.9576]\n",
      " [ 0.3799  0.6201]\n",
      " [ 0.0594  0.9406]]\n",
      "Iteration 4, predictions:\n",
      "[[ 0.0267  0.9733]\n",
      " [ 0.0435  0.9565]\n",
      " [ 0.0267  0.9733]\n",
      " ..., \n",
      " [ 0.0379  0.9621]\n",
      " [ 0.3549  0.6451]\n",
      " [ 0.0531  0.9469]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: generator 'CatBoost._staged_predict' raised StopIteration\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "predictions_gen = model.staged_predict_proba(data=X_validation, ntree_start=0, ntree_end=5, eval_period=1)\n",
    "for iteration, predictions in enumerate(predictions_gen):\n",
    "    print('Iteration ' + str(iteration) + ', predictions:')\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric evaluation on a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate metrics directly after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = model.eval_metrics(data=pool1, metrics=['Logloss','AUC'], plot=True)\n",
    "metrics = model.eval_metrics(data=pool1, metrics=['Logloss','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC values:\n",
      "[ 0.4999  0.6183  0.878   0.9372  0.9332  0.9456  0.9505  0.9542  0.9548\n",
      "  0.9562  0.9561  0.9578  0.9665  0.9667  0.9668  0.9668  0.9703  0.9706\n",
      "  0.9719  0.9716  0.9726  0.9729  0.9728  0.9729  0.973   0.973   0.973\n",
      "  0.9744  0.9743  0.9753  0.9782  0.9782  0.9782  0.9782  0.9782  0.9782\n",
      "  0.9781  0.9781  0.9779  0.9818]\n"
     ]
    }
   ],
   "source": [
    "print('AUC values:')\n",
    "print(np.array(metrics['AUC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12:**\n",
    "\n",
    "Now train a model in the following way:\n",
    "\n",
    "`\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    logging_level='Verbose'\n",
    ")\n",
    "`\n",
    "\n",
    "What will be the AUC value on 550 iteration if evaluation metrics on the initial X dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6335962\ttest: 0.6340206\tbest: 0.6340206 (0)\ttotal: 159ms\tremaining: 2m 38s\n",
      "100:\tlearn: 0.1609553\ttest: 0.1447964\tbest: 0.1447964 (100)\ttotal: 15.8s\tremaining: 2m 20s\n",
      "200:\tlearn: 0.1558555\ttest: 0.1411513\tbest: 0.1411513 (200)\ttotal: 31.3s\tremaining: 2m 4s\n",
      "300:\tlearn: 0.1509529\ttest: 0.1391401\tbest: 0.1391292 (297)\ttotal: 49.4s\tremaining: 1m 54s\n",
      "400:\tlearn: 0.1482021\ttest: 0.1391781\tbest: 0.1389002 (376)\ttotal: 1m 10s\tremaining: 1m 44s\n",
      "500:\tlearn: 0.1461119\ttest: 0.1389435\tbest: 0.1389002 (376)\ttotal: 1m 28s\tremaining: 1m 27s\n",
      "600:\tlearn: 0.1447044\ttest: 0.1389096\tbest: 0.1388514 (578)\ttotal: 1m 44s\tremaining: 1m 9s\n",
      "700:\tlearn: 0.1433795\ttest: 0.1388408\tbest: 0.1387642 (659)\ttotal: 2m\tremaining: 51.6s\n",
      "800:\tlearn: 0.1420680\ttest: 0.1387766\tbest: 0.1386987 (763)\ttotal: 2m 17s\tremaining: 34.1s\n",
      "900:\tlearn: 0.1412555\ttest: 0.1388566\tbest: 0.1386987 (763)\ttotal: 2m 34s\tremaining: 16.9s\n",
      "999:\tlearn: 0.1400826\ttest: 0.1389358\tbest: 0.1386987 (763)\ttotal: 2m 50s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1386986824\n",
      "bestIteration = 763\n",
      "\n",
      "Shrink model to first 764 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e5c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "#     logging_level='Verbose',\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task auc_550 is: 0.9849756977745989\n"
     ]
    }
   ],
   "source": [
    "metrics = model.eval_metrics(data=pool1, metrics=['AUC'])\n",
    "auc_value = np.array(metrics['AUC'][550])\n",
    "grader.submit_tag('auc_550', auc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will learn how to understand which features are the most important ones. Let's first train the model that will not use feature combinations. To forbid feature combinations you need to use 'max_ctr_complexity=1'. This will speed up the training by a lot, but it will reduce the resulting quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5443376\ttotal: 113ms\tremaining: 33.9s\n",
      "50:\tlearn: 0.1711369\ttotal: 5.54s\tremaining: 27s\n",
      "100:\tlearn: 0.1671705\ttotal: 11s\tremaining: 21.6s\n",
      "150:\tlearn: 0.1649220\ttotal: 16.9s\tremaining: 16.7s\n",
      "200:\tlearn: 0.1632912\ttotal: 22.9s\tremaining: 11.3s\n",
      "250:\tlearn: 0.1622900\ttotal: 28.9s\tremaining: 5.65s\n",
      "299:\tlearn: 0.1613767\ttotal: 34.8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e1d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    max_ctr_complexity=1,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X, y,\n",
    "    cat_features=cat_features,\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which features are most important for the model without feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MGR_ID', 32.298927496642214), ('RESOURCE', 18.516094148023672), ('ROLE_FAMILY_DESC', 12.987791972755684), ('ROLE_ROLLUP_2', 9.009528339227415), ('ROLE_DEPTNAME', 8.502603783338843), ('ROLE_CODE', 6.465296066682523), ('ROLE_FAMILY', 5.144914966956651), ('ROLE_TITLE', 5.076292845877568), ('ROLE_ROLLUP_1', 1.9985503804954317)]\n"
     ]
    }
   ],
   "source": [
    "importances = model.get_feature_importance(prettified=True)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 13: **\n",
    "\n",
    "Try training the model without the restriction of combinations, with other parameters set to the same values.\n",
    "What will be top 3 most important features for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5454508\ttotal: 147ms\tremaining: 44.1s\n",
      "50:\tlearn: 0.1562605\ttotal: 7.14s\tremaining: 34.9s\n",
      "100:\tlearn: 0.1493646\ttotal: 14.8s\tremaining: 29.1s\n",
      "150:\tlearn: 0.1451569\ttotal: 23.1s\tremaining: 22.8s\n",
      "200:\tlearn: 0.1432905\ttotal: 31.1s\tremaining: 15.3s\n",
      "250:\tlearn: 0.1417401\ttotal: 39.1s\tremaining: 7.63s\n",
      "299:\tlearn: 0.1402619\ttotal: 47s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee182e4e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    max_ctr_complexity=4,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X, y,\n",
    "    cat_features=cat_features,\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RESOURCE', 24.73509920590257), ('MGR_ID', 17.449161787258667), ('ROLE_DEPTNAME', 15.316223709876839), ('ROLE_ROLLUP_2', 11.490154799409593), ('ROLE_TITLE', 10.71183545081703), ('ROLE_FAMILY_DESC', 8.946143168072846), ('ROLE_FAMILY', 4.379723768290924), ('ROLE_CODE', 3.772023536810539), ('ROLE_ROLLUP_1', 3.199634573560977)]\n"
     ]
    }
   ],
   "source": [
    "importances = model.get_feature_importance(prettified=True)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task feature_importance_top3 is: ['RESOURCE', 'MGR_ID', 'ROLE_DEPTNAME']\n"
     ]
    }
   ],
   "source": [
    "top3 = ['RESOURCE', 'MGR_ID', 'ROLE_DEPTNAME']\n",
    "grader.submit_tag('feature_importance_top3', top3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5443376\ttotal: 138ms\tremaining: 41.2s\n",
      "50:\tlearn: 0.1711369\ttotal: 5.19s\tremaining: 25.3s\n",
      "100:\tlearn: 0.1671705\ttotal: 10.4s\tremaining: 20.5s\n",
      "150:\tlearn: 0.1649220\ttotal: 15.8s\tremaining: 15.6s\n",
      "200:\tlearn: 0.1632912\ttotal: 21.3s\tremaining: 10.5s\n",
      "250:\tlearn: 0.1622900\ttotal: 26.9s\tremaining: 5.25s\n",
      "299:\tlearn: 0.1613767\ttotal: 32.3s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee1828860>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    max_ctr_complexity=1,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X, y,\n",
    "    cat_features=cat_features,\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library provides a way to understand which features are important for a given object.\n",
    "Let's take a look on the whole dataset X and analyze the influence of different features on the objects from this dataset.\n",
    "We will now calculate importances for each object. After that we will visualize these importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing trees...\n",
      "128/300 trees processed\tpassed time: 43.3ms\tremaining time: 58.2ms sec\n",
      "300/300 trees processed\tpassed time: 127ms\tremaining time: 0us sec\n",
      "Processing documents...\n",
      "128/32769 documents processed\tpassed time: 5.51ms\tremaining time: 1.41s sec\n",
      "10112/32769 documents processed\tpassed time: 256ms\tremaining time: 573ms sec\n",
      "20096/32769 documents processed\tpassed time: 499ms\tremaining time: 315ms sec\n",
      "30080/32769 documents processed\tpassed time: 758ms\tremaining time: 67.8ms sec\n",
      "(32769, 10)\n"
     ]
    }
   ],
   "source": [
    "pool1 = Pool(data=X, label=y, cat_features=cat_features)\n",
    "shap_values = model.get_feature_importance(data=pool1, fstr_type='ShapValues', verbose=10000)\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look on the prediction of the model for 0-th object. The raw prediction is not the probability, to calculate probability from raw prediction you need to calculate sigmoid(raw_prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of class 1 = 0.9899\n",
      "Formula raw prediction = 4.5822\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_objects = [X.iloc[0:1]]\n",
    "\n",
    "for obj in test_objects:\n",
    "    print('Probability of class 1 = {:.4f}'.format(model.predict_proba(obj)[0][1]))\n",
    "    print('Formula raw prediction = {:.4f}'.format(model.predict(obj, prediction_type='RawFormulaVal')[0]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of all shap values are equal to the resulting raw formula predition.\n",
    "We can see on the graph that will be output below that there is a base value, which is equal for all the objects.\n",
    "And almost all the feature have positive influence on this object. The biggest step to the right is because of the feature called 'MGR_ID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# shap.initjs()\n",
    "# shap.force_plot(shap_values[0,:], X.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 14: **\n",
    "\n",
    "What is the most important feature for 91-th object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task most_important is: FEATURE_NAME\n"
     ]
    }
   ],
   "source": [
    "most_important_feature = 'FEATURE_NAME'\n",
    "grader.submit_tag('most_important', most_important_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 15: **\n",
    "\n",
    "Does it have positive or negative influence? Answer 1 if positive and -1 if negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task shap_influence is: 0\n"
     ]
    }
   ],
   "source": [
    "influence_sign = 0\n",
    "grader.submit_tag('shap_influence', influence_sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view aggregated information about the influences on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph you can see that values of MGR_ID and RESOURCE features have a large negative impact for many objects.\n",
    "You can also see that RESOURCE has largest positive impact for many objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your model as a binary file. It is also possible to save the model as Python or C++ code.\n",
    "If you save the model as a binary file you can then look on the parameters with which the model was trained, including learning_rate and random_seed that are set automatically if you don't specify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_best_model = CatBoostClassifier(iterations=10)\n",
    "my_best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")\n",
    "my_best_model.save_model('catboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'Logloss', 'iterations': 10, 'logging_level': 'Silent', 'verbose': 0}\n",
      "0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "my_best_model.load_model('catboost_model.bin')\n",
    "print(my_best_model.get_params())\n",
    "print(my_best_model.random_seed_)\n",
    "print(my_best_model.learning_rate_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tune the parameters to get better speed or better quality.\n",
    "Here is the list of parameters that are important for speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of parameters that are important for speeding up the training.\n",
    "Note that changing this parameters might decrease the quality.\n",
    "1. iterations + learning rate\n",
    "By default we train for 1000 iterations. You can decrease this number, but if you decrease the number of iterations you need to increase learning rate so that the process converges. We set learning rate by default dependent on number of iterations and on your dataset, so you might just use default learning rate. But if you want to tune it, you need to know - the more iterations you have, the less should be the learning rate.\n",
    "\n",
    "2. boosting_type\n",
    "By default we use Ordered boosting for smaller datasets where we want to fight overfitting. This is expensive in terms of computations. You can set boosting_type to Plain to disable this.\n",
    "\n",
    "3. bootstrap_type\n",
    "By default we sample weights from exponential distribution. It is faster to use sampling from Bernoulli distribution. To enable that use bootstrap_type='Bernoulli' + subsample={some value < 1}\n",
    "\n",
    "4. one_hot_max_size\n",
    "By default we use one-hot encoding only for categorical features with little amount of different values. For all other categorical features we calculate statistics. This is expensive, and one-hot encoding is cheap. So you can speed up the training by setting one_hot_max_size to some bigger value\n",
    "\n",
    "5. rsm\n",
    "This parameter is very important, because it speeds up the training and does not affect the quality. So you should definitely use it, but only in case if you have hundreds of features.\n",
    "If you have little amount of features it's better not to use this parameter.\n",
    "If you have many features then the rule is the following: you decrease rsm, for example, you set rsm=0.1. With this rsm value the training needs more iterations to converge. Usually you need about 20% more iterations. But each iteration will be 10x faster. So the resulting training time will be faster even though you will have more trees in the resulting model.\n",
    "\n",
    "6. leaf_estimation_iterations\n",
    "This parameter is responsible for calculating leaf values after you have already selected tree structure.\n",
    "If you have little amount of features, for example 8 or 10 features, then this place starts to be the bottle-neck.\n",
    "Default value for this parameter depends on the training objective, you can try setting it to 1 or 5, and if you have little amount of features, this might speed up the training.\n",
    "\n",
    "7. max_ctr_complexity\n",
    "By default catboost generates categorical feature combinations in a greedy way.\n",
    "This is time consuming, you can disable that by setting max_ctr_complexity=1 or by allowing only combinations of 2 features by setting max_ctr_complexity=2.\n",
    "This will speed up the training only if you have categorical features.\n",
    "\n",
    "8. If you are training the model on GPU, you can try decreasing border_count. This is the number of splits considered for each feature. By default it's set to 128, but you can try setting it to 32. In many cases it will not degrade the quality of the model and will speed up the training by a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee17a8c50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoost\n",
    "fast_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    learning_rate=0.01,\n",
    "    boosting_type='Plain',\n",
    "    bootstrap_type='Bernoulli',\n",
    "    subsample=0.5,\n",
    "    one_hot_max_size=20,\n",
    "    rsm=0.5,\n",
    "    leaf_estimation_iterations=5,\n",
    "    max_ctr_complexity=1,\n",
    "    border_count=32)\n",
    "\n",
    "fast_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    logging_level='Silent',\n",
    "#     plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 16: **\n",
    "\n",
    "Try tunning the speed of the algorithm. What is the maximum speedup you could get by changing these parameters without decreasing of AUC on best iteration on eval dataset compared to AUC on best iteration after training with default parameters and random seed = 0?\n",
    "The answer shoud be a number, for example 2.7 means you got 2.7 times speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task speedup is: 0\n"
     ]
    }
   ],
   "source": [
    "speedup = 0\n",
    "grader.submit_tag('speedup', speedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters listed below are important to get the best quality of the model. Try changing this parameters to improve the quality of the resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f5ee17a8278>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunned_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=3,\n",
    "    bagging_temperature=1,\n",
    "    random_strength=1,\n",
    "    one_hot_max_size=2,\n",
    "    leaf_estimation_method='Newton',\n",
    "    depth=6\n",
    ")\n",
    "tunned_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    logging_level='Silent',\n",
    "    eval_set=(X_validation, y_validation),\n",
    "#     plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 17: **\n",
    "\n",
    "Try tunning these parameters to make AUC on eval dataset as large as possible. What is the maximum AUC value you have reached?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task final_auc is: 0\n"
     ]
    }
   ],
   "source": [
    "final_auc = 0\n",
    "grader.submit_tag('final_auc', final_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_EMAIL = # EMAIL HERE\n",
    "STUDENT_TOKEN = # TOKEN HERE\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
